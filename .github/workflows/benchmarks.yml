name: ðŸš€ Continuous Benchmarking

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  schedule:
    # Run benchmarks daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      compare_with:
        description: 'Compare with commit/branch'
        required: false
        default: 'HEAD~1'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: "3.11"

jobs:
  benchmarks:
    name: ðŸ“Š ASV Benchmarks
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    steps:
    - name: ðŸ“¥ Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Need full history for ASV
        
    - name: ðŸ Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: âš¡ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
        
    - name: ðŸ—ï¸ Set up ASV
      run: |
        asv machine --yes
        
    - name: ðŸŽ¯ Run benchmarks (Quick)
      if: github.event_name == 'pull_request'
      run: |
        asv run --quick HEAD^!
        
    - name: ðŸŽ¯ Run benchmarks (Full)
      if: github.event_name != 'pull_request'
      run: |
        asv run HEAD^!
        
    - name: ðŸ“Š Compare benchmarks
      if: github.event_name == 'pull_request'
      run: |
        asv compare HEAD~1 HEAD --factor=1.1 --split || true
        
    - name: ðŸ“ˆ Generate benchmark report
      run: |
        asv publish
        asv preview --port 8080 --host 0.0.0.0 &
        sleep 5
        curl -f http://localhost:8080 > /dev/null || echo "Preview server failed"
        
    - name: ðŸ“¤ Upload benchmark results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results-${{ github.sha }}
        path: .asv/results/
        retention-days: 30
        
    - name: ðŸ“¤ Upload benchmark HTML
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-html-${{ github.sha }}
        path: .asv/html/
        retention-days: 30

  performance-regression:
    name: ðŸ” Performance Regression Detection
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    needs: benchmarks
    timeout-minutes: 30
    
    steps:
    - name: ðŸ“¥ Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        
    - name: ðŸ Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: âš¡ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
        
    - name: ðŸ“¥ Download benchmark results
      uses: actions/download-artifact@v4
      with:
        name: benchmark-results-${{ github.sha }}
        path: .asv/results/
        
    - name: ðŸ” Check for regressions
      run: |
        asv compare HEAD~1 HEAD --factor=1.5 --only-changed || {
          echo "::warning::Performance regression detected"
          asv compare HEAD~1 HEAD --factor=1.5 --only-changed --show-stderr
          exit 1
        }

  mutation-testing:
    name: ðŸ§¬ Mutation Testing
    runs-on: ubuntu-latest
    timeout-minutes: 45
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    
    steps:
    - name: ðŸ“¥ Checkout repository
      uses: actions/checkout@v4
      
    - name: ðŸ Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: âš¡ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
        
    - name: ðŸ§¬ Run mutation testing
      run: |
        mutmut run --paths-to-mutate src/networkx_mcp/ \
                   --tests-dir tests/unit/ \
                   --runner "python -m pytest tests/unit/ -x --tb=short" \
                   --use-coverage \
                   --CI || true
                   
    - name: ðŸ“Š Mutation testing results
      run: |
        mutmut results || true
        mutmut html || true
        
    - name: ðŸ“¤ Upload mutation results
      uses: actions/upload-artifact@v4
      with:
        name: mutation-testing-results
        path: html/
        retention-days: 30

  memory-profiling:
    name: ðŸ§  Memory Profiling
    runs-on: ubuntu-latest
    timeout-minutes: 30
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - name: ðŸ“¥ Checkout repository
      uses: actions/checkout@v4
      
    - name: ðŸ Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: âš¡ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
        pip install memory-profiler psutil
        
    - name: ðŸ§  Profile memory usage
      run: |
        python -c "
import psutil
import networkx as nx
from src.networkx_mcp.core.graph_operations import GraphManager

def profile_memory():
    process = psutil.Process()
    initial_memory = process.memory_info().rss / 1024 / 1024  # MB
    
    # Create large graphs
    gm = GraphManager()
    for i in range(5):
        G = nx.erdos_renyi_graph(1000, 0.1)
        gm.create_graph(f'graph_{i}')
        gm.graphs[f'graph_{i}'] = G
    
    peak_memory = process.memory_info().rss / 1024 / 1024  # MB
    print(f'Initial memory: {initial_memory:.2f} MB')
    print(f'Peak memory: {peak_memory:.2f} MB')
    print(f'Memory increase: {peak_memory - initial_memory:.2f} MB')
    
    return peak_memory - initial_memory

memory_increase = profile_memory()
print(f'Memory profiling complete. Increase: {memory_increase:.2f} MB')
"

  security-performance:
    name: ðŸ”’ Security Performance Testing
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
    - name: ðŸ“¥ Checkout repository
      uses: actions/checkout@v4
      
    - name: ðŸ Set up Python ${{ env.PYTHON_VERSION }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: âš¡ Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"
        
    - name: ðŸ”’ Run security performance tests
      run: |
        python -m pytest tests/security/ \
          --benchmark-only \
          --benchmark-sort=mean \
          --benchmark-json=security_benchmarks.json \
          -v
          
    - name: ðŸ“¤ Upload security benchmark results
      uses: actions/upload-artifact@v4
      with:
        name: security-benchmarks
        path: security_benchmarks.json
        retention-days: 7

  benchmark-summary:
    name: ðŸ“‹ Benchmark Summary
    runs-on: ubuntu-latest
    needs: [benchmarks, performance-regression]
    if: always()
    
    steps:
    - name: ðŸ“Š Create summary
      run: |
        echo "## ðŸš€ Benchmark Results Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Component | Status |" >> $GITHUB_STEP_SUMMARY
        echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| ASV Benchmarks | ${{ needs.benchmarks.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Performance Regression | ${{ needs.performance-regression.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ðŸ“ˆ Key Metrics" >> $GITHUB_STEP_SUMMARY
        echo "- Benchmark artifacts available for 30 days" >> $GITHUB_STEP_SUMMARY
        echo "- Regression threshold: 1.5x performance degradation" >> $GITHUB_STEP_SUMMARY
        echo "- Memory profiling enabled for main branch" >> $GITHUB_STEP_SUMMARY